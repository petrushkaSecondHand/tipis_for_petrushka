{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ee8114-da20-4396-be8c-b13ec170ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "file_path = r'C:\\Users\\Oleg\\Documents\\bank\\table1.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "df = data.copy()\n",
    "\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "df = df.drop(columns=['student_id'])\n",
    "\n",
    "df = df.fillna(0)\n",
    "\n",
    "train_df, temp_df = train_test_split(df, test_size=0.4, random_state=1)\n",
    "validation_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=1)\n",
    "\n",
    "vectorizer = DictVectorizer(sparse=True)\n",
    "X_train = vectorizer.fit_transform(train_df.to_dict(orient='records'))\n",
    "X_validation = vectorizer.transform(validation_df.to_dict(orient='records'))\n",
    "X_test = vectorizer.transform(test_df.to_dict(orient='records'))\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Validation: {X_validation.shape}, Test: {X_test.shape}\")\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "target = 'jamb_score'\n",
    "features = [col for col in df.columns if col != target]\n",
    "\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "X_train = vectorizer.fit_transform(train_df[features].to_dict(orient='records'))\n",
    "y_train = train_df[target]\n",
    "\n",
    "tree_model = DecisionTreeRegressor(max_depth=1, random_state=1)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "tree_rules = export_text(tree_model, feature_names=vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"Правило разбиения в дереве решений (глубина=1):\")\n",
    "print(tree_rules)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "y_validation = validation_df[target]\n",
    "X_validation = vectorizer.transform(validation_df[features].to_dict(orient='records'))\n",
    "\n",
    "random_forest = RandomForestRegressor(\n",
    "    n_estimators=10,\n",
    "    random_state=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred = random_forest.predict(X_validation)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_validation, y_pred))\n",
    "\n",
    "print(f\"RMSE на валидационных данных: {rmse:.2f}\")\n",
    "\n",
    "n_estimators_values = list(range(10, 201, 10))\n",
    "\n",
    "rmse_values = {}\n",
    "\n",
    "for n_estimators in n_estimators_values:\n",
    "\n",
    "    random_forest = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        random_state=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    random_forest.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = random_forest.predict(X_validation)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_validation, y_pred))\n",
    "\n",
    "    rmse_values[n_estimators] = rmse\n",
    "\n",
    "for n_estimators, rmse in rmse_values.items():\n",
    "    print(f\"n_estimators = {n_estimators}, RMSE = {rmse:.3f}\")\n",
    "\n",
    "best_n_estimators = min(rmse_values, key=rmse_values.get)\n",
    "print(f\"Значение n_estimators после которого RMSE перестает улучшаться: {best_n_estimators}\")\n",
    "\n",
    "max_depth_values = [10, 15, 20, 25]\n",
    "n_estimators_values = list(range(10, 201, 10))\n",
    "\n",
    "mean_rmse_values = {}\n",
    "\n",
    "for max_depth in max_depth_values:\n",
    "    rmse_list = []\n",
    "    for n_estimators in n_estimators_values:\n",
    "\n",
    "        random_forest = RandomForestRegressor(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            random_state=1,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        random_forest.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = random_forest.predict(X_validation)\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(y_validation, y_pred))\n",
    "        rmse_list.append(rmse)\n",
    "\n",
    "    mean_rmse = np.mean(rmse_list)\n",
    "    mean_rmse_values[max_depth] = mean_rmse\n",
    "\n",
    "for max_depth, mean_rmse in mean_rmse_values.items():\n",
    "    print(f\"max_depth = {max_depth}, Среднее RMSE = {mean_rmse:.3f}\")\n",
    "\n",
    "best_max_depth = min(mean_rmse_values, key=mean_rmse_values.get)\n",
    "print(f\"Лучшее значение max_depth: {best_max_depth}\")\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "random_forest = RandomForestRegressor(\n",
    "    n_estimators=10,\n",
    "    max_depth=20,\n",
    "    random_state=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "feature_importances = random_forest.feature_importances_\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "feature_importance_dict = dict(zip(feature_names, feature_importances))\n",
    "\n",
    "sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"Самый важный признак: {sorted_feature_importance[0][0]} с важностью {sorted_feature_importance[0][1]:.3f}\")\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dvalidation = xgb.DMatrix(X_validation, label=y_validation)\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dvalidation, 'eval')]\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.3,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "model_0_3 = xgb.train(xgb_params, dtrain, num_boost_round=100, evals=watchlist, early_stopping_rounds=10)\n",
    "\n",
    "y_pred_0_3 = model_0_3.predict(dvalidation)\n",
    "rmse_0_3 = np.sqrt(mean_squared_error(y_validation, y_pred_0_3))\n",
    "\n",
    "xgb_params['eta'] = 0.1\n",
    "model_0_1 = xgb.train(xgb_params, dtrain, num_boost_round=100, evals=watchlist, early_stopping_rounds=10)\n",
    "\n",
    "y_pred_0_1 = model_0_1.predict(dvalidation)\n",
    "rmse_0_1 = np.sqrt(mean_squared_error(y_validation, y_pred_0_1))\n",
    "\n",
    "print(f\"RMSE с eta=0.3: {rmse_0_3:.3f}\")\n",
    "print(f\"RMSE с eta=0.1: {rmse_0_1:.3f}\")\n",
    "\n",
    "if rmse_0_3 < rmse_0_1:\n",
    "    print(\"Лучшее значение eta: 0.3\")\n",
    "elif rmse_0_1 < rmse_0_3:\n",
    "    print(\"Лучшее значение eta: 0.1\")\n",
    "else:\n",
    "    print(\"Обе модели дают одинаковое значение RMSE\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
